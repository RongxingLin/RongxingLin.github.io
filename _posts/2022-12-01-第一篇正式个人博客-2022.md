# <center>AlexNet复现</center>

## 一.模型搭建

```python
import torch
import torch.nn as nn

class AlexNet(nn.Module):
    # 搭建网络主干
    def __init__(self, classes = 1000):
        super(AlexNet, self).__init__()
        self.learn_feature = nn.Sequential(
            nn.Conv2d(3, 96, 11, 4, 2),nn.ReLU(inplace = True),
            nn.MaxPool2d(3,2),
            nn.Conv2d(96, 256, 5, 1, 2),nn.ReLU(inplace = True),
            nn.MaxPool2d(3, 2),
            nn.Conv2d(256, 384, 3, 1, 1),nn.ReLU(inplace = True),
            nn.Conv2d(384, 384, 3, 1, 1),nn.ReLU(inplace = True),
            nn.Conv2d(384, 256, 3, 1, 1),nn.ReLU(inplace = True),
            nn.MaxPool2d(3, 2)
        )
        self.classifier = nn.Sequential(
            nn.Dropout(p = 0.5),
            nn.Linear(256*6*6, 4096),nn.ReLU(inplace = True),
            nn.Dropout(p = 0.5),
            nn.Linear(4096, 4096),nn.ReLU(inplace = True),
            nn.Linear(4096, classes)
        )
    # 前向传播
    def forward(self, x):
        x = self.learn_feature(x)
        # 在进入全连接层之前，需要将数据扁平化处理：有两种方式
        # 方式一：view函数
        # batch_size = x.size(0)
        # x = x.view(batch_size, -1)
        # 方式二：torch.flatten(x, start_dim = 1)
        x = torch.flatten(x, start_dim = 1)
        y = self.classifier(x)
        return y
    # 自定义是否初始化weight和bias函数
    def initialize_weigths(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, a=0, mode = 'fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
```

#### 1. nn.Sequential()：

[pytorch官方链接](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)

1. 它是一个序列容器，是`nn.Module`的子类。 `nn.Sequential` 中的层是有顺序的，而且严格按照其顺序执行，相邻两个层连接必须保证前一个层的输出与后一个层的输入相匹配。
2. Sequential的forward()方法**接受任何输入**并将其转发给它所包含的第一个模块。然后，它按顺序将每个后续模块的输出与输入 "串联 "起来，最后**返回最后一个模块的输出**。

与**手动调用模块序列**相比，**序列**提供的价值在于它允许将整个容器视为一个单一的模块，不用再逐个手动调用执行每一层网络

![](D:\image\classic_models\AlexNet\1-1-1.1.png)

nn.Sequential的用法：

```python
# Using Sequential to create a small model. When `model` is run,
# input will first be passed to `Conv2d(1,20,5)`. The output of
# `Conv2d(1,20,5)` will be used as the input to the first
# `ReLU`; the output of the first `ReLU` will become the input
# for `Conv2d(20,64,5)`. Finally, the output of
# `Conv2d(20,64,5)` will be used as input to the second `ReLU`
model = nn.Sequential(
          nn.Conv2d(1,20,5),
          nn.ReLU(),
          nn.Conv2d(20,64,5),
          nn.ReLU()
        )

# Using Sequential with OrderedDict. This is functionally the
# same as the above code
model = nn.Sequential(OrderedDict([
          ('conv1', nn.Conv2d(1,20,5)),
          ('relu1', nn.ReLU()),
          ('conv2', nn.Conv2d(20,64,5)),
          ('relu2', nn.ReLU())
        ]))
```

#### 2. 扁平化flatten

**方式一：view()**

```python
batch_size = x.size(0)	#获取batch size，x: (batch_size, channel, height, width)
x = x.view(batch_size, -1)	
```

**方式二：torch.flatten()**

```python
x = torch.flatten(x, start_dim = 1) # 第0维是batch_size，所以从第1维开始
```

#### 3. self.modules()

返回一个网络中所有模块的迭代器。

## 二.模型训练

```python
import os
import sys
import json

import torch
import torch.nn as nn
from torchvision import transforms, datasets, utils
import matplotlib.pyplot as plt
import numpy as np
import torch.optim as optim
from tqdm import tqdm

from alexnet import AlexNet


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))

    data_transform = {
        "train": transforms.Compose([transforms.RandomResizedCrop(224),
                                     transforms.RandomHorizontalFlip(),
                                     transforms.ToTensor(),
                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
        "val": transforms.Compose([transforms.Resize((224, 224)),  # cannot 224, must (224, 224)
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}
    # data_root = os.path.abspath(os.path.join(os.getcwd(), "../.."))  # get data root path
    image_path = os.path.join(os.getcwd(), "data_set")  # flower data set path
    assert os.path.exists(image_path), "{} path does not exist.".format(image_path)
    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, "train"),
                                         transform=data_transform["train"])
    train_num = len(train_dataset)

    # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}
    flower_list = train_dataset.class_to_idx
    cla_dict = dict((val, key) for key, val in flower_list.items())
    # write dict into json file
    json_str = json.dumps(cla_dict, indent=4)
    with open('class_indices.json', 'w') as json_file:
        json_file.write(json_str)

    batch_size = 32
    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers
    print('Using {} dataloader workers every process'.format(nw))

    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=batch_size, shuffle=True,
                                               num_workers=nw)

    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, "val"),
                                            transform=data_transform["val"])
    val_num = len(validate_dataset)
    validate_loader = torch.utils.data.DataLoader(validate_dataset,
                                                  batch_size=4, shuffle=False,
                                                  num_workers=nw)

    print("using {} images for training, {} images for validation.".format(train_num,
                                                                           val_num))
    # test_data_iter = iter(validate_loader)
    # test_image, test_label = test_data_iter.next()
    #
    # def imshow(img):
    #     img = img / 2 + 0.5  # unnormalize
    #     npimg = img.numpy()
    #     plt.imshow(np.transpose(npimg, (1, 2, 0)))
    #     plt.show()
    #
    # print(' '.join('%5s' % cla_dict[test_label[j].item()] for j in range(4)))
    # imshow(utils.make_grid(test_image))

    net = AlexNet(classes=5, init_weights=True)

    net.to(device)
    loss_function = nn.CrossEntropyLoss()
    # pata = list(net.parameters())
    optimizer = optim.Adam(net.parameters(), lr=0.0002)

    epochs = 10
    save_path = './AlexNet.pth' # 模型参数保存的路径
    best_acc = 0.0
    train_steps = len(train_loader)
    for epoch in range(epochs):
        # train
        net.train()
        running_loss = 0.0
        train_bar = tqdm(train_loader, file=sys.stdout,colour='green')
        for step, data in enumerate(train_bar):
            images, labels = data
            optimizer.zero_grad()
            outputs = net(images.to(device))
            loss = loss_function(outputs, labels.to(device))
            loss.backward()
            optimizer.step()
            # print statistics
            running_loss += loss.item()
            train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1, epochs, loss)

        # validate
        net.eval()
        acc = 0.0  # accumulate accurate number / epoch
        with torch.no_grad():
            val_bar = tqdm(validate_loader, file=sys.stdout,colour='blue')
            for val_data in val_bar:
                val_images, val_labels = val_data
                outputs = net(val_images.to(device))
                predict_y = torch.max(outputs, dim=1)[1]
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()
        val_accurate = acc / val_num
        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %
              (epoch + 1, running_loss / train_steps, val_accurate))
        if val_accurate > best_acc:
            best_acc = val_accurate
            torch.save(net.state_dict(), save_path)

    print('Finished Training')


if __name__ == '__main__':
    main()

```

#### 1.os标准库一些操作

##### 	1）os.getcwd()

​		功能：返回当前进程的工作目录

​		帮助记忆：getcwd —> get Current Work Documen

##### 	 2）os.path.join(path1[, path2, ...])

​		功能： 把目录和文件名合成一个路径并返回

##### 	3）os.path.abspath(path)

​		功能：返回绝对路径

##### 	4）os.path.exists(path)

​		功能：如果路径 path 存在，返回 True；如果路径 path 不存在或损坏，返回 False。

#### 2.assert断言

Python assert（断言）用于判断一个表达式，在表达式条件为 false 的时候触发异常。

断言可以在条件不满足程序运行的情况下直接返回错误，而不必等待程序运行后出现崩溃的情况，例如我们的代码只能在 Linux 系统下运行，可以先判断当前系统是否符合条件。

```python
# 语法
assert expression [, arguments]
# 若expression为True，则正常往下执行；
# 若expression为False，则抛出AssertionError,并将arguments打印出来
```

等价于

```python
if not expression:
    raise AssertionError(arguments)
```

**举例**

```python
assert 1==2, '1不等于2'

# 等价于

if not 1==2:
    raise AssertionError('1不等于2')
```

#### 3.torchvision.datasets.ImageFolder()

一个通用的数据加载器，继承自DataFolder

**注意: 虽然ImageFolder继承自DataFolder，但是其基类都来自torch.utils.data.Dataset，因此都可以用Dataset的一些方法，例如len(dataset)获取数据集的大小**

**表达式**

```python
dataset=torchvision.datasets.ImageFolder(
                       root, transform=None, 
                       target_transform=None, 
                       loader=<function default_loader>, 
                       is_valid_file=None)
```

**参数详情**

- root：图片存储的根目录，即各类别文件夹所在目录的上一级目录。
- transform：对图片进行预处理的操作（函数），原始图片作为输入，返回一个转换后的图片。
- target_transform：对图片类别进行预处理的操作，输入为 target，输出对其的转换。如果不传该参数，即对target不做任何转换，返回的顺序索引 0,1, 2…
- loader：表示数据集加载方式，通常默认加载方式即可。
- is_valid_file：获取图像文件的路径并检查该文件是否为有效文件的函数(用于检查损坏文件)

**返回值**

- self.classes：用一个 list 保存类别名称
- self.class_to_idx：类别对应的索引，与不做任何转换返回的 target 对应
- self.imgs：保存(img-path, class) tuple的 list

#### 4.Python JSON

JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式，易于人阅读和编写。

使用 JSON 函数需要导入 json 库：**import json**。

|    函数    |                 描述                 |
| :--------: | :----------------------------------: |
| json.dumps |     将Python对象编码成JSON字符串     |
| json.loads | 将已编码的JSON字符串解码为Python对象 |

**json类型转换到python类型对照表**

|     JSON     |  Python   |
| :----------: | :-------: |
|    object    |   dict    |
|    array     |   list    |
|    string    |  unicode  |
| number(int)  | int, long |
| number(real) |   float   |
|     true     |   True    |
|    false     |   False   |
|     null     |   None    |

#### 5.with as

在Python中，使用with as语句操作上下文管理器（context manager），它能够帮助我们自动分配并且释放资源。简单的理解，同时包含 __enter__() 和 __exit__() 方法的对象就是上下文管理器。

使用 with as 操作已经打开的文件对象（本身就是上下文管理器），无论期间是否抛出异常，都能保证 with as 语句执行完毕后自动关闭已经打开的文件。

with as语句的基本语法格式为：

```python
with expression[as target]:
    代码块
```

此格式中，用 [] 括起来的部分可以使用，也可以省略。其中，target 参数用于指定一个变量，该语句会将 expression 指定的结果保存到该变量中。with as 语句中的代码块如果不想执行任何语句，可以直接使用 pass 语句代替。

**举例**

```python
# 往class_indices.json文件中写入数据
with open('class_indices.json', 'w') as json_file:
	json_file.write(json_str)
```

#### 6.torch.utils.data.DataLoader()

**函数原型**

```python
DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,
           batch_sampler=None, num_workers=0, collate_fn=None,
           pin_memory=False, drop_last=False, timeout=0,
           worker_init_fn=None, *, prefetch_factor=2,
           persistent_workers=False)
```

**功能：**该接口主要用来将自定义的数据读取接口的输出或者PyTorch已有的数据读取接口的输入**按照batch size封装成Tensor**，后续只需要再包装成Variable即可作为模型的输入，因此该接口有点承上启下的作用**

**参数**

- **dataset** (*Dataset*) – 加载数据的数据集。
- **batch_size** (*int*, optional) – 每个batch加载多少个样本(默认: 1)。
- **shuffle** (*bool*, optional) – 设置为`True`时会在每个epoch重新打乱数据(默认: False).
- **sampler** (*Sampler*, optional) – 定义从数据集中提取样本的策略，即生成index的方式，可以顺序也可以乱序
- **num_workers** (*int*, optional) – 用多少个子进程加载数据。0表示数据将在主进程中加载(默认: 0)
- **collate_fn** (*callable*, optional) –将一个batch的数据和标签进行合并操作。
- **pin_memory** (*bool*, optional) –设置pin_memory=True，则意味着生成的Tensor数据最开始是属于内存中的锁页内存，这样将内存的Tensor转义到GPU的显存就会更快一些。
- **drop_last** (*bool*, optional) – 如果数据集大小不能被batch size整除，则设置为True后可删除最后一个不完整的batch。如果设为False并且数据集的大小不能被batch size整除，则最后一个batch将更小。(默认: False)
- **timeout**，是用来设置数据读取的超时时间的，但超过这个时间还没读取到数据的话就会报错。

#### 7.tqdm

1) `Tqdm `是 `Python` [进度条](https://so.csdn.net/so/search?q=进度条&spm=1001.2101.3001.7020)库，可以在 `Python `长循环中添加一个进度提示信息。用户只需要封装任意的[迭代器](https://so.csdn.net/so/search?q=迭代器&spm=1001.2101.3001.7020)，是一个快速、扩展性强的进度条工具库。

2) 功能：tqdm是一个智能进度表，它能够显示所有可迭代对象当前执行的进度。

3) 简单使用：给tqdm传入一个可迭代对象，再对tqdm再遍历即可实现进度条功能。

```markdown
1.tqdm的进度条展示是采用file初始化的输出流来进行输出的，file默认值是sys.stderr.
2.python中自带的print函数默认的输出流为sys.stdout.

3.sys.stderr和std.stdout都是默认向屏幕输出，两者的区别如下：
	1）stdout是行缓冲的，它的输出会放在一个buffer里面，只有到换行时，才会输出到屏幕；
	2）stderr是无缓冲的，会直接输出。

4.由第3点可知，tqdm和print都是向屏幕输出，因此两者交替使用时可能会导致输出的内容交杂。
	解决方法：
	① 使用tqdm本身提供的write方法代替print输出。
	tqdm.write()跟print的区别是使用了with做了一些上下文处理，点击进入external_write_mode中，可以知道在write之前external_write_mode对已经展示的进度条进行clear操作，在write之后对复原clear的进度条。这就保证了进度条永远在用户打印的内容之下。
```



#### 8.net.train()、net.eval()

注意：“net.train()”和“net.eval()”中的net是你实例模型变量名，是你自定义的。

神经网络模块存在两种模式，train模式（net.train())和eval模式（net.eval())。**一般的神经网络中，这两种模式是一样的，只有当模型中存在dropout操作和batchnorm操作的时候才有区别**。

a) **net.eval()**，**不启用 BatchNormalization 和 Dropout。**此时pytorch会自动把BN和DropOut固定住，不会取平均，而是用训练好的值。不然的话，一旦test的batch_size过小，很容易就会因BN层导致模型performance损失较大；

b) **net.train()** ：**启用 BatchNormalization 和 Dropout。** 在模型测试阶段使用model.train() 让model变成训练模式，此时 dropout和batch normalization的操作在训练q起到防止网络过拟合的问题。

因此，在使用PyTorch进行训练和测试时一定要记得给实例化的model指定train/eval。

model.eval() 负责改变batchnorm、dropout的工作方式，如在eval()模式下，dropout是不工作的。

#### 9.torch.max()

函数原型：torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)

功能：按维度dim 返回最大值，并且返回索引。

```markdown
torch.max()[0]， 只返回最大值的每个数

troch.max()[1]， 只返回最大值的每个索引

torch.max()[1].data 只返回variable中的数据部分（去掉Variable containing:）

torch.max()[1].data.numpy() 把数据转化成numpy ndarry

torch.max()[1].data.numpy().squeeze() 把数据条目中维度为1 的删除掉

```

#### 10.torch.eq()

**函数原型：**torch.eq(input, other, *, out=None)	—> Tensor

对两个张量Tensor进行逐元素的比较，若相同位置的两个元素相同，则返回True；若不同，返回False。

**参数：**

- input：必须是一个Tensor，该张量用于比较
- other ：可以是一个张量Tensor，也可以是一个值value

**返回值：**

返回一个Boolean类型的张量，对两个张量Tensor进行逐元素的比较，若相同位置的两个元素相同，则返回True；若不同，返回False。

#### 11.torch.save()

**功能：**torch.save()用于保存训练好的模型

保存模型主要分为两类：

1. 保存整个模型，网络结构+权重参数（不推荐）

   ```python
   # 语法
   torch.save(model, 'net_path') # net_path是自定义的保存路径
   ```

2. 只保存模型的参数

   ```python
   # 语法
   torch.save(model.state_dict(), 'net_parameter_path')
   ```

如何使用保存好的模型？

1. 对于保存整个模型

   ```python
   model = torch.load('net_path')	# net_path是自定义的保存路径
   ```

2. 对于只保存模型的参数

   ```python
   # 第一步：实例化一个空的模型
   new_model = myModel()
   # 第二步：获取已保存的模型参数
   state_dict = torch.load('net_parameter_path')
   # torch.load返回的是一个OrderedDict,说明.state_dict()只是把所有模型的参数都已OrderedDict的形式存下来。
   # 第三步：将已保存的模型参数加载到新的模型中
   new_model.load_state_dict(state_dict)
   
   # 建议：将load_state_dict()中的strict参数设置为False
   new_model.load_state_dict(state_dict, strict=False)
   、、、
   好处：如果哪一天我们需要重新写这个网络的，比如使用new_model,如果直接load会出现unexpected key. 但是加上strict=False可以很容易地加载预训练的参数（注意检查key是否匹配），直接忽略不匹配的key,对于匹配的key则进行正常的赋值。 
   、、、
   ```

   **补充：**可以[自定义需要save的内容](https://blog.csdn.net/weixin_38145317/article/details/111152491)

   

## 三、模型测试

```python
import os
import json

import torch
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt

from alexnet import AlexNet


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    data_transform = transforms.Compose(
        [transforms.Resize((224, 224)),
         transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    # load image
    img_path = os.path.join(os.getcwd(),"data_set","roses.jpg")
    assert os.path.exists(img_path), "file: '{}' dose not exist.".format(img_path)
    img = Image.open(img_path)

    plt.imshow(img)
    # [N, C, H, W]
    img = data_transform(img)
    # expand batch dimension
    img = torch.unsqueeze(img, dim=0)

    # read class_indict
    json_path = './class_indices.json'
    assert os.path.exists(json_path), "file: '{}' dose not exist.".format(json_path)

    with open(json_path, "r") as f:
        class_indict = json.load(f)

    # create model
    model = AlexNet(classes=5).to(device)

    # load model weights
    weights_path = "./AlexNet.pth"
    assert os.path.exists(weights_path), "file: '{}' dose not exist.".format(weights_path)
    model.load_state_dict(torch.load(weights_path))

    model.eval()
    with torch.no_grad():
        # predict class
        output = torch.squeeze(model(img.to(device))).cpu()
        print(output)
        predict = torch.softmax(output, dim=0)
        print(predict)
        predict_cla = torch.argmax(predict).numpy()

    print_res = "class: {}   prob: {:.3}".format(class_indict[str(predict_cla)],
                                                 predict[predict_cla].numpy())
    plt.title(print_res)
    for i in range(len(predict)):
        print("class: {:10}   prob: {:.3}".format(class_indict[str(i)],
                                                  predict[i].numpy()))
    plt.show()


if __name__ == '__main__':
    main()

```

#### 1.output.cpu()

此时output仍然在显存中，而内存操作可能会找不到该变量，也就是说，show(output)是没办法进行操作的。那么**cpu()出现了**。

- 作用：将数据移至CPU中
- 返回值：Tensor

#### 2.torch.softmax()

**函数原型：**

```python
torch.nn.functional.softmax(*input*, *dim=None*, *_stacklevel=3*, *dtype=None*)
```

$$
\begin{align}
	Softnax(x_i) = \frac {e^{x_i}} {\sum_{j=1}^{c}e^{x_j}}
\end{align}
$$

softmax函数：又称**归一化指数函数**，是二分类函数[sigmoid](https://so.csdn.net/so/search?q=sigmoid&spm=1001.2101.3001.7020)在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。

作用：型已经有分类预测结果以后，将预测结果输入softmax函数，进行非负性和归一化处理，最后得到0-1之内的分类概率。

**参数：**

- input(tensor): 输入的数据
- dim(int): 指定在哪个维度进行Softmax操作（如果没有指定，默认dim=1）。

[参考文章1：一文详解SoftMax函数](https://zhuanlan.zhihu.com/p/105722023)

[解析torch.nn.Softmax()中的参数dim](https://blog.csdn.net/weixin_49883619/article/details/121880326)

#### 3.torch.argmax()

**函数原型：**

```python
torch.argmax(input, dim=None, keepdim=False)
```

**作用：**返回指定维度最大值的序号。

**参数：**

- input：输入的tensor
- dim：dim的取值为[-2, 1]之间，只能取整，有四个数，0和-2对应，得到的是每一列的最大值，1和-1对应，得到的是每一行的最大值。如果参数中不写dim，则得到的是张量中最大的值对应的索引（从0开始）。

